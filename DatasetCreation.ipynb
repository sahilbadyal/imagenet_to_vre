{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from random import sample\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('syntoword.json', 'r') as f:\n",
    "    syntoword = json.load(f)\n",
    "with open('attribMap.json', 'r') as f:\n",
    "    attribMap = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) ## Done for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_collage(input_dir, collage_size):\n",
    "    '''\n",
    "    This function creates the 3 X 3 collage of randomly sampled images from the input directory\n",
    "    '''\n",
    "    r, c = collage_size\n",
    "    images_outers= []\n",
    "    image_names = []\n",
    "    for i in range(r):\n",
    "        images = []\n",
    "        for image_name in sample(os.listdir(input_dir), c):\n",
    "            image_names.append(image_name)\n",
    "            image = cv2.imread(os.path.join(input_dir, image_name))\n",
    "            try:\n",
    "                image = cv2.resize(image, (300, 200)) #If something fails here\n",
    "            except:\n",
    "                print(image_name)\n",
    "            images.append(image)\n",
    "        image_outer = np.hstack(images)\n",
    "        images_outers.append(image_outer)\n",
    "    return ((np.vstack(images_outers)), image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hardcoded location references only if the attributres are not present \n",
    "location_ref = {\n",
    "    0: \"on the top left\",\n",
    "    1: \"on the top\",\n",
    "    2: \"on the top right\",\n",
    "    3: \"to the left\",\n",
    "    4: \"in the middle\",\n",
    "    5: \"to the right\",\n",
    "    6: \"on the bottom left\",\n",
    "    7: \"on the bottom\",\n",
    "    8: \"on thebottom right\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounding_boxes = {\n",
    "    0: [0,0, 300, 200],\n",
    "    1: [300,0, 300, 200],\n",
    "    2: [600,0, 300, 200],\n",
    "    3: [0,200, 300, 200],\n",
    "    4: [300, 200, 300, 200],\n",
    "    5: [600, 200, 300, 200],\n",
    "    6: [0, 400, 300, 200],\n",
    "    7: [300, 400, 300, 200],\n",
    "    8: [600, 400, 300, 200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markFaultyFiles(input_dir):\n",
    "    '''\n",
    "    This function marks the faulty/damaged/corrupt images that are present in the input dir\n",
    "    '''\n",
    "    image_names = []\n",
    "    for image_name in os.listdir(input_dir):\n",
    "        image = cv2.imread(os.path.join(input_dir, image_name))\n",
    "        try:\n",
    "            image = cv2.resize(image, (300, 200))\n",
    "        except:\n",
    "            #print(image_name)\n",
    "            image_names.append(image_name)\n",
    "    return image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteFiles(inp_dir, files):\n",
    "    '''\n",
    "    Deletes the files in a directory\n",
    "    '''\n",
    "    for file in files:\n",
    "        os.remove(os.path.join(inp_dir,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRefStatement(id_, syn, synid):\n",
    "    '''\n",
    "    Basic function that creates a reference statement from the image arrtibues and its synset name\n",
    "    http://image-net.org/download-attributes\n",
    "    '''\n",
    "    global location_ref\n",
    "    objectNames = syntoword[syn]\n",
    "    if len(objectNames) == 0:\n",
    "        return \"\"\n",
    "    i  = np.random.randint(0,len(objectNames))\n",
    "    ref = \"the\"\n",
    "    attrib = \" \"\n",
    "    if len(attribMap[synid]['attrib']) != 0:\n",
    "        if len(attribMap[synid]['attrib']) == 1:\n",
    "            attrib += attribMap[synid]['attrib'][0]\n",
    "        else:\n",
    "            attrib += \", \".join(attribMap[synid]['attrib'][:-1])\n",
    "            if(len(attribMap[synid]['attrib']) >2):\n",
    "                attrib += \", \"\n",
    "            else:\n",
    "                attrib += \" \"\n",
    "            attrib += \"and \" + attribMap[synid]['attrib'][-1]\n",
    "        ref += attrib + \" \" + objectNames[i]\n",
    "    else:\n",
    "        try:\n",
    "            ref +=  \" \" + objectNames[i] + \" \" + location_ref[id_]\n",
    "        except:\n",
    "            #print(objectNames,i,syn, synid)\n",
    "            pass\n",
    "    return ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkAndCreateDirectory(direc, create=True):\n",
    "    '''\n",
    "    This function checks if a directory exits and creates it if the flag is true\n",
    "    '''\n",
    "    if os.path.isdir(direc):\n",
    "        return True\n",
    "    if create:\n",
    "        os.mkdir(direc)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataset(inp_dir, out_dir, length=130):\n",
    "    '''\n",
    "    The main loop that created the dataset and stores the information in the output directory\n",
    "    \n",
    "    '''\n",
    "    total_files = 0\n",
    "    inputcheck = checkAndCreateDirectory(inp_dir, False)\n",
    "    if not inputcheck:\n",
    "        raise ValueError(f\"Input directory {inp_dir} does not exist. Exiting...\")\n",
    "    checkAndCreateDirectory(out_dir)\n",
    "    \n",
    "    global bounding_boxes\n",
    "    \n",
    "    reference_image = \"ref_image_\"\n",
    "    output_dataset = {}\n",
    "\n",
    "    output_dataset['boxes'] = []\n",
    "    output_dataset['images'] = []\n",
    "\n",
    "    for key in bounding_boxes:\n",
    "        bb = {}\n",
    "        bb['box_id'] = key\n",
    "        bb['name'] = ''\n",
    "        bb['width'] = bounding_boxes[key][2]\n",
    "        bb['height'] = bounding_boxes[key][3]\n",
    "        bb['x'] = bounding_boxes[key][0]\n",
    "        bb['y'] = bounding_boxes[key][1]\n",
    "        output_dataset['boxes'].append(bb)\n",
    "\n",
    "    for i in range(length):\n",
    "        #print(i)\n",
    "        image, images = create_collage(inp_dir, (3,3))\n",
    "        datum = {}\n",
    "        image_name  = reference_image + str(i)\n",
    "        datum['filename'] = image_name\n",
    "        datum['reference_pairs']  = []\n",
    "        previous_ref = [] ## there should not be same reference in the same collage\n",
    "        for j,img in enumerate(images):\n",
    "            synid = img.split('.')[0]\n",
    "            syn  = synid.split('_')[0]\n",
    "            bb = {\n",
    "                'boundingBox_id':j\n",
    "            }\n",
    "            ref = createRefStatement(j, syn, synid)\n",
    "            if ref == \"\":\n",
    "                print(img)\n",
    "                continue\n",
    "            if ref not in previous_ref:\n",
    "                total_files += 1\n",
    "                bb['reference'] = ref\n",
    "            else:\n",
    "                continue\n",
    "            previous_ref.append(ref)\n",
    "            datum['reference_pairs'].append(bb)\n",
    "        output_dataset['images'].append(datum)\n",
    "        cv2.imwrite(f\"{os.path.join(out_dir,image_name)}.jpg\", image)\n",
    "    print(f\"Total Datapoints Generated  = {total_files}\")\n",
    "    return output_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveDataset(out_dir,output_dataset):\n",
    "    with open(out_dir+\"vre_dataset.json\", 'w') as f:\n",
    "        json.dump(output_dataset,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Datapoints Generated  = 2874\n"
     ]
    }
   ],
   "source": [
    "input_directory  = \"./data/\"\n",
    "output_directory = \"./dataset_v3/\"\n",
    "\n",
    "# Delete the faulty files, sanity check\n",
    "#deleteFiles(input_directory,markFaultyFiles(input_directory))\n",
    "\n",
    "## create the dataset\n",
    "\n",
    "ds = createDataset(input_directory,output_directory,length=320)\n",
    "\n",
    "## Save the dataset\n",
    "saveDataset(output_directory, ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
